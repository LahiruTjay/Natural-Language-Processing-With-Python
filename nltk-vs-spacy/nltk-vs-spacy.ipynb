{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK vs spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Tokenization (Sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data/sample_text.txt\", \"r\", encoding=\"utf8\")\n",
    "text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29363155000312174 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "\n",
    "sent_tokens = sent_tokenize(text)\n",
    "sentences = [sent for sent in sent_tokens]\n",
    "\n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2420803837097818 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "\n",
    "doc = nlp(text)\n",
    "sentences = [sent for sent in doc.sents]\n",
    "\n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Tokenization (Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004767292983252069 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "\n",
    "word_tokens = word_tokenize(text)\n",
    "words = [word_token for word_token in word_tokens]\n",
    "\n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014553756915953286 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "\n",
    "doc = nlp(text)\n",
    "words = [token.text for token in doc]\n",
    "\n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3744629953207994 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "\n",
    "word_tokens = word_tokenize(text)\n",
    "pos_tag(word_tokens)\n",
    "\n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'tagger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The ﻿The    ﻿Xxx False False\n",
      "performance performance    xxxx True False\n",
      "of of    xx True True\n",
      "these this    xxxx True True\n",
      "simple simple    xxxx True False\n",
      "machine machine    xxxx True False\n",
      "learning learn    xxxx True False\n",
      "algorithms algorithm    xxxx True False\n",
      "depends depend    xxxx True False\n",
      "heavily heavily    xxxx True False\n",
      "on on    xx True True\n",
      "the the    xxx True True\n",
      "representation representation    xxxx True False\n",
      "of of    xx True True\n",
      "the the    xxx True True\n",
      "data datum    xxxx True False\n",
      "they they    xxxx True True\n",
      "are be    xxx True True\n",
      "given give    xxxx True False\n",
      ". .    . False False\n",
      "For For    Xxx True False\n",
      "example example    xxxx True False\n",
      ", ,    , False False\n",
      "when when    xxxx True True\n",
      "logistic logistic    xxxx True False\n",
      "regression regression    xxxx True False\n",
      "is be    xx True True\n",
      "used use    xxxx True True\n",
      "to to    xx True True\n",
      "recommend recommend    xxxx True False\n",
      "cesarean cesarean    xxxx True False\n",
      "delivery delivery    xxxx True False\n",
      ", ,    , False False\n",
      "the the    xxx True True\n",
      "AI AI    XX True False\n",
      "system system    xxxx True False\n",
      "does doe    xxxx True True\n",
      "not not    xxx True True\n",
      "examinethe examinethe    xxxx True False\n",
      "patient patient    xxxx True False\n",
      "directly directly    xxxx True False\n",
      ". .    . False False\n",
      "Instead Instead    Xxxxx True False\n",
      ", ,    , False False\n",
      "the the    xxx True True\n",
      "doctor doctor    xxxx True False\n",
      "tells tell    xxxx True False\n",
      "the the    xxx True True\n",
      "system system    xxxx True False\n",
      "several several    xxxx True True\n",
      "pieces piece    xxxx True False\n",
      "of of    xx True True\n",
      "relevant relevant    xxxx True False\n",
      "information information    xxxx True False\n",
      ", ,    , False False\n",
      "such such    xxxx True True\n",
      "as a    xx True True\n",
      "the the    xxx True True\n",
      "presence presence    xxxx True False\n",
      "or or    xx True True\n",
      "absence absence    xxxx True False\n",
      "of of    xx True True\n",
      "a a    x True True\n",
      "uterine uterine    xxxx True False\n",
      "scar scar    xxxx True False\n",
      ". .    . False False\n",
      "Each Each    Xxxx True False\n",
      "piece piece    xxxx True False\n",
      "of of    xx True True\n",
      "information information    xxxx True False\n",
      "included include    xxxx True False\n",
      "in in    xx True True\n",
      "the the    xxx True True\n",
      "representation representation    xxxx True False\n",
      "of of    xx True True\n",
      "the the    xxx True True\n",
      "patient patient    xxxx True False\n",
      "is be    xx True True\n",
      "known know    xxxx True False\n",
      "as a    xx True True\n",
      "afeature afeature    xxxx True False\n",
      ". .    . False False\n",
      "Logistic Logistic    Xxxxx True False\n",
      "regression regression    xxxx True False\n",
      "learns learn    xxxx True False\n",
      "how how    xxx True True\n",
      "each each    xxxx True True\n",
      "of of    xx True True\n",
      "these this    xxxx True True\n",
      "features feature    xxxx True False\n",
      "of of    xx True True\n",
      "the the    xxx True True\n",
      "patient patient    xxxx True False\n",
      "correlates correlate    xxxx True False\n",
      "with with    xxxx True True\n",
      "various various    xxxx True True\n",
      "outcomes outcome    xxxx True False\n",
      ". .    . False False\n",
      "However However    Xxxxx True False\n",
      ", ,    , False False\n",
      "it it    xx True True\n",
      "can can VERB MD  xxx True True\n",
      "not not ADV RB  xxx True True\n",
      "inﬂuence inﬂuence    xxxx True False\n",
      "how how    xxx True True\n",
      "features feature    xxxx True False\n",
      "are be    xxx True True\n",
      "deﬁned deﬁned    xxxx True False\n",
      "in in    xx True True\n",
      "anyway anyway    xxxx True True\n",
      ". .    . False False\n",
      "If If    Xx True False\n",
      "logistic logistic    xxxx True False\n",
      "regression regression    xxxx True False\n",
      "were be    xxxx True True\n",
      "given give    xxxx True False\n",
      "an a    xx True True\n",
      "MRI MRI    XXX True False\n",
      "scan scan    xxxx True False\n",
      "of of    xx True True\n",
      "the the    xxx True True\n",
      "patient patient    xxxx True False\n",
      ", ,    , False False\n",
      "rather rather    xxxx True True\n",
      "thanthe thanthe    xxxx True False\n",
      "doctor doctor    xxxx True False\n",
      "’s ’s    ’x False False\n",
      "formalized formalize    xxxx True False\n",
      "report report    xxxx True False\n",
      ", ,    , False False\n",
      "it it    xx True True\n",
      "would would    xxxx True True\n",
      "not not    xxx True True\n",
      "be be    xx True True\n",
      "able able    xxxx True False\n",
      "to to    xx True True\n",
      "make make    xxxx True True\n",
      "useful useful    xxxx True False\n",
      "predictions prediction    xxxx True False\n",
      ". .    . False False\n",
      "Individual Individual    Xxxxx True False\n",
      "pixels pixel    xxxx True False\n",
      "in in    xx True True\n",
      "an a    xx True True\n",
      "MRI MRI    XXX True False\n",
      "scan scan    xxxx True False\n",
      "have have    xxxx True True\n",
      "negligible negligible    xxxx True False\n",
      "correlation correlation    xxxx True False\n",
      "with with    xxxx True True\n",
      "any any    xxx True True\n",
      "complications complication    xxxx True False\n",
      "that that    xxxx True True\n",
      "might may    xxxx True True\n",
      "occur occur    xxxx True False\n",
      "during during    xxxx True True\n",
      "delivery delivery    xxxx True False\n",
      ". .    . False False\n",
      "This This    Xxxx True False\n",
      "dependence dependence    xxxx True False\n",
      "on on    xx True True\n",
      "representations representation    xxxx True False\n",
      "is be    xx True True\n",
      "a a    x True True\n",
      "general general    xxxx True False\n",
      "phenomenon phenomenon    xxxx True False\n",
      "that that    xxxx True True\n",
      "appears appear    xxxx True False\n",
      "throughout throughout    xxxx True True\n",
      "computer computer    xxxx True False\n",
      "science science    xxxx True False\n",
      "and and    xxx True True\n",
      "even even    xxxx True True\n",
      "daily daily    xxxx True False\n",
      "life life    xxxx True False\n",
      ". .    . False False\n",
      "In In    Xx True False\n",
      "computer computer    xxxx True False\n",
      "science science    xxxx True False\n",
      ", ,    , False False\n",
      "operations operation    xxxx True False\n",
      "such such    xxxx True True\n",
      "as a    xx True True\n",
      "searching search    xxxx True False\n",
      "a a    x True True\n",
      "collection collection    xxxx True False\n",
      "of of    xx True True\n",
      "data datum    xxxx True False\n",
      "can can    xxx True True\n",
      "proceed proceed    xxxx True False\n",
      "exponentially exponentially    xxxx True False\n",
      "faster fast    xxxx True False\n",
      "if if    xx True True\n",
      "the the    xxx True True\n",
      "collection collection    xxxx True False\n",
      "is be    xx True True\n",
      "structured structure    xxxx True False\n",
      "and and    xxx True True\n",
      "indexed index    xxxx True False\n",
      "intelligently intelligently    xxxx True False\n",
      ". .    . False False\n",
      "People People    Xxxxx True False\n",
      "can can    xxx True True\n",
      "easily easily    xxxx True False\n",
      "perform perform    xxxx True False\n",
      "arithmetic arithmetic    xxxx True False\n",
      "on on    xx True True\n",
      "Arabic Arabic    Xxxxx True False\n",
      "numerals numeral    xxxx True False\n",
      "but but    xxx True True\n",
      "ﬁnd ﬁnd    xxx True False\n",
      "arithmetic arithmetic    xxxx True False\n",
      "on on    xx True True\n",
      "Roman Roman    Xxxxx True False\n",
      "numerals numeral    xxxx True False\n",
      "much much    xxxx True True\n",
      "more much    xxxx True True\n",
      "time time    xxxx True False\n",
      "consuming consume    xxxx True False\n",
      ". .    . False False\n",
      "It It    Xx True False\n",
      "is be    xx True True\n",
      "not not    xxx True True\n",
      "surprising surprise    xxxx True False\n",
      "that that    xxxx True True\n",
      "the the    xxx True True\n",
      "choice choice    xxxx True False\n",
      "of of    xx True True\n",
      "representation representation    xxxx True False\n",
      "has have    xxx True True\n",
      "an a    xx True True\n",
      "enormous enormous    xxxx True False\n",
      "eﬀect eﬀect    xxxx True False\n",
      "on on    xx True True\n",
      "the the    xxx True True\n",
      "performance performance    xxxx True False\n",
      "of of    xx True True\n",
      "machine machine    xxxx True False\n",
      "learning learn    xxxx True False\n",
      "algorithms algorithm    xxxx True False\n",
      ". .    . False False\n",
      "For For    Xxx True False\n",
      "a a    x True True\n",
      "simple simple    xxxx True False\n",
      "visual visual    xxxx True False\n",
      "example example    xxxx True False\n",
      ", ,    , False False\n",
      "see see    xxx True True\n",
      "ﬁgure ﬁgure    xxxx True False\n",
      "1.1 1.1    d.d False False\n",
      ". .    . False False\n",
      "Many Many    Xxxx True False\n",
      "artiﬁcial artiﬁcial    xxxx True False\n",
      "intelligence intelligence    xxxx True False\n",
      "tasks task    xxxx True False\n",
      "can can    xxx True True\n",
      "be be    xx True True\n",
      "solved solve    xxxx True False\n",
      "by by    xx True True\n",
      "designing design    xxxx True False\n",
      "the the    xxx True True\n",
      "right right    xxxx True False\n",
      "set set    xxx True False\n",
      "offeatures offeatures    xxxx True False\n",
      "to to    xx True True\n",
      "extract extract    xxxx True False\n",
      "for for    xxx True True\n",
      "that that    xxxx True True\n",
      "task task    xxxx True False\n",
      ", ,    , False False\n",
      "then then    xxxx True True\n",
      "providing provide    xxxx True False\n",
      "these this    xxxx True True\n",
      "features feature    xxxx True False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to to    xx True True\n",
      "a a    x True True\n",
      "simple simple    xxxx True False\n",
      "machine machine    xxxx True False\n",
      "learning learn    xxxx True False\n",
      "algorithm algorithm    xxxx True False\n",
      ". .    . False False\n",
      "For For    Xxx True False\n",
      "example example    xxxx True False\n",
      ", ,    , False False\n",
      "a a    x True True\n",
      "useful useful    xxxx True False\n",
      "feature feature    xxxx True False\n",
      "for for    xxx True True\n",
      "speaker speaker    xxxx True False\n",
      "identiﬁcation identiﬁcation    xxxx True False\n",
      "from from    xxxx True True\n",
      "sound sound    xxxx True False\n",
      "is be    xx True True\n",
      "an a    xx True True\n",
      "estimate estimate    xxxx True False\n",
      "of of    xx True True\n",
      "the the    xxx True True\n",
      "size size    xxxx True False\n",
      "of of    xx True True\n",
      "the the    xxx True True\n",
      "speaker speaker  "
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u'Apple is looking at buying Colombo based startup for $1 billion')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    " \n",
    "doc = nlp('I just bought 2 shares of Apple at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ')\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('I am Lahiru and I just bought 2 Apples at 9 a.m. from the Apple Inc. before the current stock went up by 1 billion $')\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"These are apples. These are oranges.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    " \n",
    "doc = nlp('Wall Street Journal just published a piece on crypto currencies')\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 80})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Wall Street Journal just published an interesting piece on crypto currencies\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.label_, chunk.root.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u'I love coffee')\n",
    "print(doc.vocab.strings[u'coffee'])  # 3197928453018144401\n",
    "print(doc.vocab.strings[3197928453018144401])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('I love coffee')\n",
    "for word in doc:\n",
    "    lexeme = doc.vocab[word.text]\n",
    "    print(lexeme.text, lexeme.orth, lexeme.shape_, lexeme.prefix_, lexeme.suffix_,\n",
    "          lexeme.is_alpha, lexeme.is_digit, lexeme.is_title, lexeme.lang_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = nlp(\"Cats are beautiful animals.\")\n",
    " \n",
    "doc1 = nlp(\"Dogs are awesome.\")\n",
    "doc2 = nlp(\"Some gorgeous creatures are felines.\")\n",
    "doc3 = nlp(\"Dolphins are swimming mammals.\")\n",
    " \n",
    "print(target.similarity(doc1))  # 0.8901765218466683\n",
    "print(target.similarity(doc2))  # 0.9115828449161616\n",
    "print(target.similarity(doc3))  # 0.782295675287610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "          chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
