{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK vs spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''The performance of these simple machine learning algorithms depends heavily on the representation of the data they are given. For example, when logisticregression is used to recommend cesarean delivery, the AI system does not examinethe patient directly. Instead, the doctor tells the system several pieces of relevantinformation, such as the presence or absence of a uterine scar. Each piece ofinformation included in the representation of the patient is known as afeature.Logistic regression learns how each of these features of the patient correlates withvarious outcomes. However, it cannot inﬂuence how features are deﬁned in anyway. If logistic regression were given an MRI scan of the patient, rather thanthe doctor’s formalized report, it would not be able to make useful predictions.Individual pixels in an MRI scan have negligible correlation with any complications that might occur during delivery.This dependence on representations is a general phenomenon that appearsthroughout computer science and even daily life. In computer science, operationssuch as searching a collection of data can proceed exponentially faster if the collec-tion is structured and indexed intelligently. People can easily perform arithmeticon Arabic numerals but ﬁnd arithmetic on Roman numerals much more timeconsuming. It is not surprising that the choice of representation has an enormouseﬀect on the performance of machine learning algorithms. For a simple visualexample, see ﬁgure 1.1.Many artiﬁcial intelligence tasks can be solved by designing the right set offeatures to extract for that task, then providing these features to a simple machinelearning algorithm. For example, a useful feature for speaker identiﬁcation fromsound is an estimate of the size of the speaker’s vocal tract. This feature gives astrong clue as to whether the speaker is a man, woman, or child'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004537189559588484 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "\n",
    "word_tokens = word_tokenize(text)\n",
    "words = [word_token for word_token in word_tokens]\n",
    "\n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01969037636864357 seconds\n",
      "['The', 'performance', 'of', 'these', 'simple', 'machine', 'learning', 'algorithms', 'depends', 'heavily', 'on', 'the', 'representation', 'of', 'the', 'data', 'they', 'are', 'given', '.', 'For', 'example', ',', 'when', 'logisticregression', 'is', 'used', 'to', 'recommend', 'cesarean', 'delivery', ',', 'the', 'AI', 'system', 'does', 'not', 'examinethe', 'patient', 'directly', '.', 'Instead', ',', 'the', 'doctor', 'tells', 'the', 'system', 'several', 'pieces', 'of', 'relevantinformation', ',', 'such', 'as', 'the', 'presence', 'or', 'absence', 'of', 'a', 'uterine', 'scar', '.', 'Each', 'piece', 'ofinformation', 'included', 'in', 'the', 'representation', 'of', 'the', 'patient', 'is', 'known', 'as', 'afeature', '.', 'Logistic', 'regression', 'learns', 'how', 'each', 'of', 'these', 'features', 'of', 'the', 'patient', 'correlates', 'withvarious', 'outcomes', '.', 'However', ',', 'it', 'can', 'not', 'inﬂuence', 'how', 'features', 'are', 'deﬁned', 'in', 'anyway', '.', 'If', 'logistic', 'regression', 'were', 'given', 'an', 'MRI', 'scan', 'of', 'the', 'patient', ',', 'rather', 'thanthe', 'doctor', '’s', 'formalized', 'report', ',', 'it', 'would', 'not', 'be', 'able', 'to', 'make', 'useful', 'predictions', '.', 'Individual', 'pixels', 'in', 'an', 'MRI', 'scan', 'have', 'negligible', 'correlation', 'with', 'any', 'complications', 'that', 'might', 'occur', 'during', 'delivery', '.', 'This', 'dependence', 'on', 'representations', 'is', 'a', 'general', 'phenomenon', 'that', 'appearsthroughout', 'computer', 'science', 'and', 'even', 'daily', 'life', '.', 'In', 'computer', 'science', ',', 'operationssuch', 'as', 'searching', 'a', 'collection', 'of', 'data', 'can', 'proceed', 'exponentially', 'faster', 'if', 'the', 'collec', '-', 'tion', 'is', 'structured', 'and', 'indexed', 'intelligently', '.', 'People', 'can', 'easily', 'perform', 'arithmeticon', 'Arabic', 'numerals', 'but', 'ﬁnd', 'arithmetic', 'on', 'Roman', 'numerals', 'much', 'more', 'timeconsuming', '.', 'It', 'is', 'not', 'surprising', 'that', 'the', 'choice', 'of', 'representation', 'has', 'an', 'enormouseﬀect', 'on', 'the', 'performance', 'of', 'machine', 'learning', 'algorithms', '.', 'For', 'a', 'simple', 'visualexample', ',', 'see', 'ﬁgure', '1.1.Many', 'artiﬁcial', 'intelligence', 'tasks', 'can', 'be', 'solved', 'by', 'designing', 'the', 'right', 'set', 'offeatures', 'to', 'extract', 'for', 'that', 'task', ',', 'then', 'providing', 'these', 'features', 'to', 'a', 'simple', 'machinelearning', 'algorithm', '.', 'For', 'example', ',', 'a', 'useful', 'feature', 'for', 'speaker', 'identiﬁcation', 'fromsound', 'is', 'an', 'estimate', 'of', 'the', 'size', 'of', 'the', 'speaker', '’s', 'vocal', 'tract', '.', 'This', 'feature', 'gives', 'astrong', 'clue', 'as', 'to', 'whether', 'the', 'speaker', 'is', 'a', 'man', ',', 'woman', ',', 'or', 'child']\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "\n",
    "doc = nlp(text)\n",
    "words = [token.text for token in doc]\n",
    "\n",
    "print(time.clock() - start_time, \"seconds\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.0010006427764892578 seconds ---\n",
      "The performance of these simple machine learning algorithms depends heavily on the representation of the data they are given.\n",
      "For example, when logisticregression is used to recommend cesarean delivery, the AI system does not examinethe patient directly.\n",
      "Instead, the doctor tells the system several pieces of relevantinformation, such as the presence or absence of a uterine scar.\n",
      "Each piece ofinformation included in the representation of the patient is known as afeature.Logistic regression learns how each of these features of the patient correlates withvarious outcomes.\n",
      "However, it cannot inﬂuence how features are deﬁned in anyway.\n",
      "If logistic regression were given an MRI scan of the patient, rather thanthe doctor’s formalized report, it would not be able to make useful predictions.Individual pixels in an MRI scan have negligible correlation with any complications that might occur during delivery.This dependence on representations is a general phenomenon that appearsthroughout computer science and even daily life.\n",
      "In computer science, operationssuch as searching a collection of data can proceed exponentially faster if the collec-tion is structured and indexed intelligently.\n",
      "People can easily perform arithmeticon Arabic numerals but ﬁnd arithmetic on Roman numerals much more timeconsuming.\n",
      "It is not surprising that the choice of representation has an enormouseﬀect on the performance of machine learning algorithms.\n",
      "For a simple visualexample, see ﬁgure 1.1.Many artiﬁcial intelligence tasks can be solved by designing the right set offeatures to extract for that task, then providing these features to a simple machinelearning algorithm.\n",
      "For example, a useful feature for speaker identiﬁcation fromsound is an estimate of the size of the speaker’s vocal tract.\n",
      "This feature gives astrong clue as to whether the speaker is a man, woman, or child\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "words = [sentence for sentence in sentences]\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "for sentence in words:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "doc = nlp(text)\n",
    "words = [sent for sent in doc.sents]\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "for sentence in words:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion. And people still wonder why?')\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u'Apple is looking at buying Colombo based startup for $1 billion')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    " \n",
    "doc = nlp('I just bought 2 shares of Apple at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ')\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('I am Lahiru and I just bought 2 Apples at 9 a.m. from the Apple Inc. before the current stock went up by 1 billion $')\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"These are apples. These are oranges.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    " \n",
    "doc = nlp('Wall Street Journal just published a piece on crypto currencies')\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 80})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Wall Street Journal just published an interesting piece on crypto currencies\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.label_, chunk.root.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u'I love coffee')\n",
    "print(doc.vocab.strings[u'coffee'])  # 3197928453018144401\n",
    "print(doc.vocab.strings[3197928453018144401])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('I love coffee')\n",
    "for word in doc:\n",
    "    lexeme = doc.vocab[word.text]\n",
    "    print(lexeme.text, lexeme.orth, lexeme.shape_, lexeme.prefix_, lexeme.suffix_,\n",
    "          lexeme.is_alpha, lexeme.is_digit, lexeme.is_title, lexeme.lang_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = nlp(\"Cats are beautiful animals.\")\n",
    " \n",
    "doc1 = nlp(\"Dogs are awesome.\")\n",
    "doc2 = nlp(\"Some gorgeous creatures are felines.\")\n",
    "doc3 = nlp(\"Dolphins are swimming mammals.\")\n",
    " \n",
    "print(target.similarity(doc1))  # 0.8901765218466683\n",
    "print(target.similarity(doc2))  # 0.9115828449161616\n",
    "print(target.similarity(doc3))  # 0.782295675287610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "          chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
